{
    "learning_rate": 1e-3,
    "warmup_portion": 0.1,
    "max_grad_norm": -1,
    "has_relative_attention_bias": false,
    "relative_attention_num_buckets": 0,
    "d_ff": 10,
    "d_kv": 8,
    "transformer_input_size": 8,
    "num_head": 2,
    "transformer_blocks": 2,
    "batch_size": 256,
    "num_epochs": 100,
    "dropout": 0.1,
    "predict_batch": 128,
    "num_loss": 1,
    "weighted_sampler": false
}
